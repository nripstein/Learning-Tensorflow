{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-06-20T01:14:51.688364Z",
     "start_time": "2023-06-20T01:14:48.467159Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf # pip install tensorflow-macos\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Introduction to Milestone Project 2: SkimLit\n",
    "###Problem in a sentence\n",
    "- The number of RCT papers released is continuing to increase, those without structured abstracts can be hard to read and in turn slow down researchers moving through the literature.\n",
    "\n",
    "###Solution in a sentence\n",
    "- Create an NLP model to classify abstract sentences into the role they play (e.g. objective, methods, results, etc) to enable researchers to skim through the literature (hence SkimLit) and dive deeper when necessary.\n",
    "\n",
    "Where our data is coming from: PubMed 200k RCT: a Dataset for Sequential Sentence Classification in Medical Abstracts\n",
    "Where our model is coming from: [*Neural networks for joint sentence\n",
    "classification in medical paper abstracts*](https://arxiv.org/pdf/1612.05251.pdf).\n",
    "\n",
    "## Abstract of paper outlining model we'll implement:\n",
    "We present PubMed 200k RCT, a new dataset based on PubMed for sequential sentence classification. The dataset consists of approximately 200,000 abstracts of randomized controlled trials, totaling 2.3 million sentences. Each sentence of each abstract is labeled with their role in the abstract using one of the following classes: background, objective, method, result, or conclusion. The purpose of releasing this dataset is twofold. First, the majority of datasets for sequential short-text classification (i.e., classification of short texts that appear in sequences) are small: we hope that releasing a new large dataset will help develop more accurate algorithms for this task. Second, from an application perspective, researchers need better tools to efficiently skim through the literature. Automatically classifying each sentence in an abstract would help researchers read abstracts more efficiently, especially in fields where abstracts may be long, such as the medical field."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# What we're going to cover\n",
    "Time to take what we've learned in the NLP fundmentals notebook and build our biggest NLP model yet:\n",
    "\n",
    "1. Downloading a text dataset (PubMed RCT200k from GitHub)\n",
    "2. Writing a preprocessing function to prepare our data for modelling\n",
    "3. Setting up a series of modelling experiments\n",
    "4. Making a baseline (TF-IDF classifier)\n",
    "5. Deep models with different combinations of: token embeddings, character embeddings, pretrained embeddings, positional embeddings\n",
    "6. Building our first multimodal model (taking multiple types of data inputs)\n",
    "7. Replicating the model architecture from https://arxiv.org/abs/1612.05251\n",
    "8. Find the most wrong predictions\n",
    "9. Making predictions on PubMed abstracts from the wild"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# SkimLit inputs and outputs\n",
    "- Identifies what category each sentence belongs to, and puts it under headers"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Loading data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "os.chdir(os.path.join(os.getcwd(), \"skimlit_data\"))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-20T01:35:45.924064Z",
     "start_time": "2023-06-20T01:35:45.918645Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'pubmed-rct'...\r\n",
      "remote: Enumerating objects: 33, done.\u001B[K\r\n",
      "remote: Counting objects: 100% (8/8), done.\u001B[K\r\n",
      "remote: Compressing objects: 100% (3/3), done.\u001B[K\r\n",
      "remote: Total 33 (delta 5), reused 5 (delta 5), pack-reused 25\u001B[K\r\n",
      "Receiving objects: 100% (33/33), 177.08 MiB | 36.40 MiB/s, done.\r\n",
      "Resolving deltas: 100% (12/12), done.\r\n",
      "\u001B[34mPubMed_200k_RCT\u001B[m\u001B[m\r\n",
      "\u001B[34mPubMed_200k_RCT_numbers_replaced_with_at_sign\u001B[m\u001B[m\r\n",
      "\u001B[34mPubMed_20k_RCT\u001B[m\u001B[m\r\n",
      "\u001B[34mPubMed_20k_RCT_numbers_replaced_with_at_sign\u001B[m\u001B[m\r\n",
      "README.md\r\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/Franck-Dernoncourt/pubmed-rct.git\n",
    "!ls pubmed-rct"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-20T01:36:01.893463Z",
     "start_time": "2023-06-20T01:35:55.768608Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dev.txt   test.txt  train.txt\r\n",
      "dev.txt   test.txt  train.txt\r\n"
     ]
    }
   ],
   "source": [
    "# Check what files are in the PubMed_20K dataset\n",
    "!ls pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign\n",
    "!ls pubmed-rct/PubMed_20k_RCT"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-20T01:36:49.380112Z",
     "start_time": "2023-06-20T01:36:49.136134Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# Start by using the 20k dataset\n",
    "data_dir = \"pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-20T01:37:07.566563Z",
     "start_time": "2023-06-20T01:37:07.563355Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "['pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/dev.txt',\n 'pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/train.txt',\n 'pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/test.txt']"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check all of the filenames in the target directory\n",
    "filenames = [data_dir + filename for filename in os.listdir(data_dir)]\n",
    "filenames"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-20T01:37:12.149690Z",
     "start_time": "2023-06-20T01:37:12.141596Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Visualizing examples from the dataset (becoming one with the data)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "# Create function to read the lines of a document\n",
    "def get_lines(filename):\n",
    "  \"\"\"\n",
    "  Reads filename (a text file) and returns the lines of text as a list.\n",
    "\n",
    "  Args:\n",
    "      filename: a string containing the target filepath to read.\n",
    "\n",
    "  Returns:\n",
    "      A list of strings with one string per line from the target filename.\n",
    "      For example:\n",
    "      [\"this is the first line of filename\",\n",
    "       \"this is the second line of filename\",\n",
    "       \"...\"]\n",
    "  \"\"\"\n",
    "  with open(filename, \"r\") as f:\n",
    "    return f.readlines()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-20T01:40:49.630328Z",
     "start_time": "2023-06-20T01:40:49.627250Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "['###24293578\\n',\n 'OBJECTIVE\\tTo investigate the efficacy of @ weeks of daily low-dose oral prednisolone in improving pain , mobility , and systemic low-grade inflammation in the short term and whether the effect would be sustained at @ weeks in older adults with moderate to severe knee osteoarthritis ( OA ) .\\n',\n 'METHODS\\tA total of @ patients with primary knee OA were randomized @:@ ; @ received @ mg/day of prednisolone and @ received placebo for @ weeks .\\n',\n 'METHODS\\tOutcome measures included pain reduction and improvement in function scores and systemic inflammation markers .\\n',\n 'METHODS\\tPain was assessed using the visual analog pain scale ( @-@ mm ) .\\n',\n 'METHODS\\tSecondary outcome measures included the Western Ontario and McMaster Universities Osteoarthritis Index scores , patient global assessment ( PGA ) of the severity of knee OA , and @-min walk distance ( @MWD ) .\\n',\n 'METHODS\\tSerum levels of interleukin @ ( IL-@ ) , IL-@ , tumor necrosis factor ( TNF ) - , and high-sensitivity C-reactive protein ( hsCRP ) were measured .\\n',\n 'RESULTS\\tThere was a clinically relevant reduction in the intervention group compared to the placebo group for knee pain , physical function , PGA , and @MWD at @ weeks .\\n',\n 'RESULTS\\tThe mean difference between treatment arms ( @ % CI ) was @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; and @ ( @-@ @ ) , p < @ , respectively .\\n',\n 'RESULTS\\tFurther , there was a clinically relevant reduction in the serum levels of IL-@ , IL-@ , TNF - , and hsCRP at @ weeks in the intervention group when compared to the placebo group .\\n',\n 'RESULTS\\tThese differences remained significant at @ weeks .\\n',\n 'RESULTS\\tThe Outcome Measures in Rheumatology Clinical Trials-Osteoarthritis Research Society International responder rate was @ % in the intervention group and @ % in the placebo group ( p < @ ) .\\n',\n 'CONCLUSIONS\\tLow-dose oral prednisolone had both a short-term and a longer sustained effect resulting in less knee pain , better physical function , and attenuation of systemic inflammation in older patients with knee OA ( ClinicalTrials.gov identifier NCT@ ) .\\n',\n '\\n',\n '###24854809\\n',\n 'BACKGROUND\\tEmotional eating is associated with overeating and the development of obesity .\\n',\n 'BACKGROUND\\tYet , empirical evidence for individual ( trait ) differences in emotional eating and cognitive mechanisms that contribute to eating during sad mood remain equivocal .\\n',\n 'OBJECTIVE\\tThe aim of this study was to test if attention bias for food moderates the effect of self-reported emotional eating during sad mood ( vs neutral mood ) on actual food intake .\\n',\n 'OBJECTIVE\\tIt was expected that emotional eating is predictive of elevated attention for food and higher food intake after an experimentally induced sad mood and that attentional maintenance on food predicts food intake during a sad versus a neutral mood .\\n',\n 'METHODS\\tParticipants ( N = @ ) were randomly assigned to one of the two experimental mood induction conditions ( sad/neutral ) .\\n']"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_lines = get_lines(data_dir+\"train.txt\")\n",
    "train_lines[:20] # the whole first example of an abstract + a little more of the next one"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-20T01:41:24.091282Z",
     "start_time": "2023-06-20T01:41:24.043099Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Different abstracts are separated by abstract ID's (lines beginning with ###) and newlines (\\n)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Writing a preprocessing function to structure our data for modelling"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "def preprocess_text_with_line_numbers(filename):\n",
    "  \"\"\"Returns a list of dictionaries of abstract line data.\n",
    "\n",
    "  Takes in filename, reads its contents and sorts through each line,\n",
    "  extracting things like the target label, the text of the sentence,\n",
    "  how many sentences are in the current abstract and what sentence number\n",
    "  the target line is.\n",
    "\n",
    "  Args:\n",
    "      filename: a string of the target text file to read and extract line data\n",
    "      from.\n",
    "\n",
    "  Returns:\n",
    "      A list of dictionaries each containing a line from an abstract,\n",
    "      the lines label, the lines position in the abstract and the total number\n",
    "      of lines in the abstract where the line is from. For example:\n",
    "\n",
    "      [{\"target\": 'CONCLUSION',\n",
    "        \"text\": The study couldn't have gone better, turns out people are kinder than you think\",\n",
    "        \"line_number\": 8,\n",
    "        \"total_lines\": 8}]\n",
    "  \"\"\"\n",
    "  input_lines = get_lines(filename) # get all lines from filename\n",
    "  abstract_lines = \"\" # create an empty abstract\n",
    "  abstract_samples = [] # create an empty list of abstracts\n",
    "\n",
    "  # Loop through each line in target file\n",
    "  for line in input_lines:\n",
    "    if line.startswith(\"###\"): # check to see if line is an ID line\n",
    "      abstract_id = line\n",
    "      abstract_lines = \"\" # reset abstract string\n",
    "    elif line.isspace(): # check to see if line is a new line\n",
    "      abstract_line_split = abstract_lines.splitlines() # split abstract into separate lines\n",
    "\n",
    "      # Iterate through each line in abstract and count them at the same time\n",
    "      for abstract_line_number, abstract_line in enumerate(abstract_line_split):\n",
    "        line_data = {} # create empty dict to store data from line\n",
    "        target_text_split = abstract_line.split(\"\\t\") # split target label from text\n",
    "        line_data[\"target\"] = target_text_split[0] # get target label\n",
    "        line_data[\"text\"] = target_text_split[1].lower() # get target text and lower it\n",
    "        line_data[\"line_number\"] = abstract_line_number # what number line does the line appear in the abstract?\n",
    "        line_data[\"total_lines\"] = len(abstract_line_split) - 1 # how many total lines are in the abstract? (start from 0)\n",
    "        abstract_samples.append(line_data) # add line data to abstract samples list\n",
    "\n",
    "    else: # if the above conditions aren't fulfilled, the line contains a labelled sentence\n",
    "      abstract_lines += line\n",
    "\n",
    "  return abstract_samples"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-20T01:46:02.565297Z",
     "start_time": "2023-06-20T01:46:02.559286Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1 µs, sys: 0 ns, total: 1 µs\n",
      "Wall time: 1.67 µs\n"
     ]
    },
    {
     "data": {
      "text/plain": "(180040, 30212, 30135)"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get data from file and preprocess it\n",
    "%time\n",
    "train_samples = preprocess_text_with_line_numbers(data_dir + \"train.txt\")\n",
    "val_samples = preprocess_text_with_line_numbers(data_dir + \"dev.txt\") # dev is another name for validation set\n",
    "test_samples = preprocess_text_with_line_numbers(data_dir + \"test.txt\")\n",
    "len(train_samples), len(val_samples), len(test_samples)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-20T01:47:50.633425Z",
     "start_time": "2023-06-20T01:47:50.370297Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "[{'target': 'OBJECTIVE',\n  'text': 'to investigate the efficacy of @ weeks of daily low-dose oral prednisolone in improving pain , mobility , and systemic low-grade inflammation in the short term and whether the effect would be sustained at @ weeks in older adults with moderate to severe knee osteoarthritis ( oa ) .',\n  'line_number': 0,\n  'total_lines': 11},\n {'target': 'METHODS',\n  'text': 'a total of @ patients with primary knee oa were randomized @:@ ; @ received @ mg/day of prednisolone and @ received placebo for @ weeks .',\n  'line_number': 1,\n  'total_lines': 11},\n {'target': 'METHODS',\n  'text': 'outcome measures included pain reduction and improvement in function scores and systemic inflammation markers .',\n  'line_number': 2,\n  'total_lines': 11},\n {'target': 'METHODS',\n  'text': 'pain was assessed using the visual analog pain scale ( @-@ mm ) .',\n  'line_number': 3,\n  'total_lines': 11},\n {'target': 'METHODS',\n  'text': 'secondary outcome measures included the western ontario and mcmaster universities osteoarthritis index scores , patient global assessment ( pga ) of the severity of knee oa , and @-min walk distance ( @mwd ) .',\n  'line_number': 4,\n  'total_lines': 11},\n {'target': 'METHODS',\n  'text': 'serum levels of interleukin @ ( il-@ ) , il-@ , tumor necrosis factor ( tnf ) - , and high-sensitivity c-reactive protein ( hscrp ) were measured .',\n  'line_number': 5,\n  'total_lines': 11},\n {'target': 'RESULTS',\n  'text': 'there was a clinically relevant reduction in the intervention group compared to the placebo group for knee pain , physical function , pga , and @mwd at @ weeks .',\n  'line_number': 6,\n  'total_lines': 11},\n {'target': 'RESULTS',\n  'text': 'the mean difference between treatment arms ( @ % ci ) was @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; and @ ( @-@ @ ) , p < @ , respectively .',\n  'line_number': 7,\n  'total_lines': 11},\n {'target': 'RESULTS',\n  'text': 'further , there was a clinically relevant reduction in the serum levels of il-@ , il-@ , tnf - , and hscrp at @ weeks in the intervention group when compared to the placebo group .',\n  'line_number': 8,\n  'total_lines': 11},\n {'target': 'RESULTS',\n  'text': 'these differences remained significant at @ weeks .',\n  'line_number': 9,\n  'total_lines': 11},\n {'target': 'RESULTS',\n  'text': 'the outcome measures in rheumatology clinical trials-osteoarthritis research society international responder rate was @ % in the intervention group and @ % in the placebo group ( p < @ ) .',\n  'line_number': 10,\n  'total_lines': 11},\n {'target': 'CONCLUSIONS',\n  'text': 'low-dose oral prednisolone had both a short-term and a longer sustained effect resulting in less knee pain , better physical function , and attenuation of systemic inflammation in older patients with knee oa ( clinicaltrials.gov identifier nct@ ) .',\n  'line_number': 11,\n  'total_lines': 11},\n {'target': 'BACKGROUND',\n  'text': 'emotional eating is associated with overeating and the development of obesity .',\n  'line_number': 0,\n  'total_lines': 10},\n {'target': 'BACKGROUND',\n  'text': 'yet , empirical evidence for individual ( trait ) differences in emotional eating and cognitive mechanisms that contribute to eating during sad mood remain equivocal .',\n  'line_number': 1,\n  'total_lines': 10}]"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the first abstract of our training data\n",
    "train_samples[:14]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-20T01:48:55.042885Z",
     "start_time": "2023-06-20T01:48:55.039535Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Performing visual data analysis on our preprocessed text"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "         target                                               text   \n0     OBJECTIVE  to investigate the efficacy of @ weeks of dail...  \\\n1       METHODS  a total of @ patients with primary knee oa wer...   \n2       METHODS  outcome measures included pain reduction and i...   \n3       METHODS  pain was assessed using the visual analog pain...   \n4       METHODS  secondary outcome measures included the wester...   \n5       METHODS  serum levels of interleukin @ ( il-@ ) , il-@ ...   \n6       RESULTS  there was a clinically relevant reduction in t...   \n7       RESULTS  the mean difference between treatment arms ( @...   \n8       RESULTS  further , there was a clinically relevant redu...   \n9       RESULTS  these differences remained significant at @ we...   \n10      RESULTS  the outcome measures in rheumatology clinical ...   \n11  CONCLUSIONS  low-dose oral prednisolone had both a short-te...   \n12   BACKGROUND  emotional eating is associated with overeating...   \n13   BACKGROUND  yet , empirical evidence for individual ( trai...   \n\n    line_number  total_lines  \n0             0           11  \n1             1           11  \n2             2           11  \n3             3           11  \n4             4           11  \n5             5           11  \n6             6           11  \n7             7           11  \n8             8           11  \n9             9           11  \n10           10           11  \n11           11           11  \n12            0           10  \n13            1           10  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>target</th>\n      <th>text</th>\n      <th>line_number</th>\n      <th>total_lines</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>OBJECTIVE</td>\n      <td>to investigate the efficacy of @ weeks of dail...</td>\n      <td>0</td>\n      <td>11</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>METHODS</td>\n      <td>a total of @ patients with primary knee oa wer...</td>\n      <td>1</td>\n      <td>11</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>METHODS</td>\n      <td>outcome measures included pain reduction and i...</td>\n      <td>2</td>\n      <td>11</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>METHODS</td>\n      <td>pain was assessed using the visual analog pain...</td>\n      <td>3</td>\n      <td>11</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>METHODS</td>\n      <td>secondary outcome measures included the wester...</td>\n      <td>4</td>\n      <td>11</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>METHODS</td>\n      <td>serum levels of interleukin @ ( il-@ ) , il-@ ...</td>\n      <td>5</td>\n      <td>11</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>RESULTS</td>\n      <td>there was a clinically relevant reduction in t...</td>\n      <td>6</td>\n      <td>11</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>RESULTS</td>\n      <td>the mean difference between treatment arms ( @...</td>\n      <td>7</td>\n      <td>11</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>RESULTS</td>\n      <td>further , there was a clinically relevant redu...</td>\n      <td>8</td>\n      <td>11</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>RESULTS</td>\n      <td>these differences remained significant at @ we...</td>\n      <td>9</td>\n      <td>11</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>RESULTS</td>\n      <td>the outcome measures in rheumatology clinical ...</td>\n      <td>10</td>\n      <td>11</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>CONCLUSIONS</td>\n      <td>low-dose oral prednisolone had both a short-te...</td>\n      <td>11</td>\n      <td>11</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>BACKGROUND</td>\n      <td>emotional eating is associated with overeating...</td>\n      <td>0</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>BACKGROUND</td>\n      <td>yet , empirical evidence for individual ( trai...</td>\n      <td>1</td>\n      <td>10</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.DataFrame(train_samples)\n",
    "test_df = pd.DataFrame(test_samples)\n",
    "val_df = pd.DataFrame(val_samples)\n",
    "train_df.head(14)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-20T01:50:35.076327Z",
     "start_time": "2023-06-20T01:50:34.896677Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "target\nMETHODS        59353\nRESULTS        57953\nCONCLUSIONS    27168\nBACKGROUND     21727\nOBJECTIVE      13839\nName: count, dtype: int64"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Distribution of labels in training data\n",
    "train_df.target.value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-20T01:50:47.741810Z",
     "start_time": "2023-06-20T01:50:47.738475Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df[\"total_lines\"].plot.hist(bins=20);"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-20T01:51:23.950349Z",
     "start_time": "2023-06-20T01:51:23.852929Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "(180040, 30212, 30135)"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert abstract text lines into lists\n",
    "train_sentences = train_df[\"text\"].tolist()\n",
    "val_sentences = val_df[\"text\"].tolist()\n",
    "test_sentences = test_df[\"text\"].tolist()\n",
    "len(train_sentences), len(val_sentences), len(test_sentences)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-20T01:51:52.400740Z",
     "start_time": "2023-06-20T01:51:52.390648Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "data": {
      "text/plain": "['to investigate the efficacy of @ weeks of daily low-dose oral prednisolone in improving pain , mobility , and systemic low-grade inflammation in the short term and whether the effect would be sustained at @ weeks in older adults with moderate to severe knee osteoarthritis ( oa ) .',\n 'a total of @ patients with primary knee oa were randomized @:@ ; @ received @ mg/day of prednisolone and @ received placebo for @ weeks .',\n 'outcome measures included pain reduction and improvement in function scores and systemic inflammation markers .',\n 'pain was assessed using the visual analog pain scale ( @-@ mm ) .',\n 'secondary outcome measures included the western ontario and mcmaster universities osteoarthritis index scores , patient global assessment ( pga ) of the severity of knee oa , and @-min walk distance ( @mwd ) .',\n 'serum levels of interleukin @ ( il-@ ) , il-@ , tumor necrosis factor ( tnf ) - , and high-sensitivity c-reactive protein ( hscrp ) were measured .',\n 'there was a clinically relevant reduction in the intervention group compared to the placebo group for knee pain , physical function , pga , and @mwd at @ weeks .',\n 'the mean difference between treatment arms ( @ % ci ) was @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; and @ ( @-@ @ ) , p < @ , respectively .',\n 'further , there was a clinically relevant reduction in the serum levels of il-@ , il-@ , tnf - , and hscrp at @ weeks in the intervention group when compared to the placebo group .',\n 'these differences remained significant at @ weeks .']"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View first 10 lines of training sentences\n",
    "train_sentences[:10]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-20T01:52:07.563208Z",
     "start_time": "2023-06-20T01:52:07.557966Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Turning our target labels into numbers (ML models require numbers)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/NoahRipstein/PycharmProjects/Tensorflow tutorial att2/venv/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": "array([[0., 0., 0., 1., 0.],\n       [0., 0., 1., 0., 0.],\n       [0., 0., 1., 0., 0.],\n       ...,\n       [0., 0., 0., 0., 1.],\n       [0., 1., 0., 0., 0.],\n       [0., 1., 0., 0., 0.]])"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One hot encode labels\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "one_hot_encoder = OneHotEncoder(sparse=False)  # should be False for TensorFlow\n",
    "train_labels_one_hot = one_hot_encoder.fit_transform(train_df[\"target\"].to_numpy().reshape(-1, 1))\n",
    "val_labels_one_hot = one_hot_encoder.transform(val_df[\"target\"].to_numpy().reshape(-1, 1))\n",
    "test_labels_one_hot = one_hot_encoder.transform(test_df[\"target\"].to_numpy().reshape(-1, 1))\n",
    "\n",
    "# Check what training labels look like\n",
    "train_labels_one_hot"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-20T01:53:48.248600Z",
     "start_time": "2023-06-20T01:53:47.624602Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "data": {
      "text/plain": "array([3, 2, 2, ..., 4, 1, 1])"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract labels (\"target\" columns) and encode them into integers\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "train_labels_encoded = label_encoder.fit_transform(train_df[\"target\"].to_numpy())\n",
    "val_labels_encoded = label_encoder.transform(val_df[\"target\"].to_numpy())\n",
    "test_labels_encoded = label_encoder.transform(test_df[\"target\"].to_numpy())\n",
    "\n",
    "# Check what training labels look like\n",
    "train_labels_encoded"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-20T01:56:11.186357Z",
     "start_time": "2023-06-20T01:56:11.161796Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "data": {
      "text/plain": "(5,\n array(['BACKGROUND', 'CONCLUSIONS', 'METHODS', 'OBJECTIVE', 'RESULTS'],\n       dtype=object))"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get class names and number of classes from LabelEncoder instance\n",
    "num_classes = len(label_encoder.classes_)\n",
    "class_names = label_encoder.classes_\n",
    "num_classes, class_names"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-20T01:56:54.582723Z",
     "start_time": "2023-06-20T01:56:54.574482Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model 0: Creating, fitting and evaluating a baseline model for SkimLit"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Create a pipeline\n",
    "model_0 = Pipeline([\n",
    "  (\"tf-idf\", TfidfVectorizer()),\n",
    "  (\"clf\", MultinomialNB())\n",
    "])\n",
    "\n",
    "# Fit the pipeline to the training data\n",
    "model_0.fit(X=train_sentences,\n",
    "            y=train_labels_encoded);"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-20T01:59:44.858225Z",
     "start_time": "2023-06-20T01:59:43.229898Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "data": {
      "text/plain": "0.7218323844829869"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate baseline on validation dataset\n",
    "model_0.score(X=val_sentences,\n",
    "              y=val_labels_encoded)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-20T01:59:57.987847Z",
     "start_time": "2023-06-20T01:59:57.712753Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "data": {
      "text/plain": "array([4, 1, 3, ..., 4, 4, 1])"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions\n",
    "baseline_preds = model_0.predict(val_sentences)\n",
    "baseline_preds"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-20T02:00:06.471304Z",
     "start_time": "2023-06-20T02:00:06.280998Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "data": {
      "text/plain": "{'accuracy': 0.7218323844829869,\n 'precision': 0.7186466952323352,\n 'recall': 0.7218323844829869,\n 'f1': 0.6989250353450294}"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import calculate_results helper function\n",
    "from helper_functions import calculate_results\n",
    "\n",
    "# Calculate baseline results\n",
    "baseline_results = calculate_results(y_true=val_labels_encoded,\n",
    "                                     y_pred=baseline_preds)\n",
    "baseline_results"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-20T02:01:55.562739Z",
     "start_time": "2023-06-20T02:01:55.536314Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Preparing our data for deep sequence models\n",
    "- But before we start building deeper models, we've got to create vectorization and embedding layers"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-20T02:03:44.073381Z",
     "start_time": "2023-06-20T02:03:44.065650Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "data": {
      "text/plain": "26.338269273494777"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How long is each sentence on average?\n",
    "sent_lens = [len(sentence.split()) for sentence in train_sentences]\n",
    "avg_sent_len = np.mean(sent_lens)\n",
    "avg_sent_len # return average sentence length (in tokens)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-20T02:03:46.645020Z",
     "start_time": "2023-06-20T02:03:46.505392Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1, 1)\n",
    "ax.hist(sent_lens, bins=100, edgecolor=\"black\", alpha=0.8);"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-20T02:04:46.277572Z",
     "start_time": "2023-06-20T02:04:45.991248Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "data": {
      "text/plain": "55"
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How long of a sentence covers 95% of the lengths?\n",
    "output_seq_len = int(np.percentile(sent_lens, 95))\n",
    "output_seq_len"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-20T02:05:35.468040Z",
     "start_time": "2023-06-20T02:05:35.463954Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "data": {
      "text/plain": "296"
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Maximum sentence length in the training set\n",
    "max(sent_lens)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-20T02:07:00.325785Z",
     "start_time": "2023-06-20T02:07:00.324069Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Creating a text vectoriser to map our tokens (text) to numbers\n",
    "- Use TensorFlow TextVectorization"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [],
   "source": [
    "# How many words are in our vocabulary? (taken from 3.2 in https://arxiv.org/pdf/1710.06071.pdf)\n",
    "max_tokens = 68000\n",
    "\n",
    "from tensorflow.keras.layers import TextVectorization\n",
    "\n",
    "text_vectorizer = TextVectorization(max_tokens=max_tokens, # number of words in vocabulary\n",
    "                                    output_sequence_length=55) # desired output length of vectorized sequences"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-20T02:09:43.931170Z",
     "start_time": "2023-06-20T02:09:43.842816Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-19 22:09:55.256313: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    }
   ],
   "source": [
    "# Adapt text vectorizer to training sentences\n",
    "text_vectorizer.adapt(train_sentences)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-20T02:09:58.081278Z",
     "start_time": "2023-06-20T02:09:54.088187Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text:\n",
      "bevacizumab , a recombinant humanized monoclonal antibody against vascular endothelial growth factor , was approved by the us food and drug administration for the treatment of advanced non-small-cell lung cancer ( nsclc ) in combination with carboplatin and paclitaxel .\n",
      "\n",
      "Length of text: 40\n",
      "\n",
      "Vectorized text:\n",
      "[[ 1034     8  2653 10727  3440  1029   644   758  1033   621   432    10\n",
      "   1824    22     2   850   661     3   300   288    11     2    19     4\n",
      "    588  4023   489   135  1783     5   269     7  3000     3  2118     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0]]\n"
     ]
    }
   ],
   "source": [
    "# Test out text vectorizer\n",
    "import random\n",
    "target_sentence = random.choice(train_sentences)\n",
    "print(f\"Text:\\n{target_sentence}\")\n",
    "print(f\"\\nLength of text: {len(target_sentence.split())}\")\n",
    "print(f\"\\nVectorized text:\\n{text_vectorizer([target_sentence])}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-20T02:11:31.198254Z",
     "start_time": "2023-06-20T02:11:31.192725Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Using the get_vocabulary() method of our text_vectorizer we can find out a few different tidbits about our text."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words in vocabulary: 64841\n",
      "Most common words in the vocabulary: ['', '[UNK]', 'the', 'and', 'of']\n",
      "Least common words in the vocabulary: ['aainduced', 'aaigroup', 'aachener', 'aachen', 'aaacp']\n"
     ]
    }
   ],
   "source": [
    "# How many words in our training vocabulary?\n",
    "rct_20k_text_vocab = text_vectorizer.get_vocabulary()\n",
    "print(f\"Number of words in vocabulary: {len(rct_20k_text_vocab)}\"),\n",
    "print(f\"Most common words in the vocabulary: {rct_20k_text_vocab[:5]}\")\n",
    "print(f\"Least common words in the vocabulary: {rct_20k_text_vocab[-5:]}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-20T02:11:28.420221Z",
     "start_time": "2023-06-20T02:11:28.351179Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [
    {
     "data": {
      "text/plain": "{'name': 'text_vectorization',\n 'trainable': True,\n 'dtype': 'string',\n 'batch_input_shape': (None,),\n 'max_tokens': 68000,\n 'standardize': 'lower_and_strip_punctuation',\n 'split': 'whitespace',\n 'ngrams': None,\n 'output_mode': 'int',\n 'output_sequence_length': 55,\n 'pad_to_max_tokens': False,\n 'sparse': False,\n 'ragged': False,\n 'vocabulary': None,\n 'idf_weights': None,\n 'encoding': 'utf-8',\n 'vocabulary_size': 64841}"
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the config of our text vectorizer\n",
    "text_vectorizer.get_config()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-20T02:12:07.008099Z",
     "start_time": "2023-06-20T02:12:07.003816Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Creating a custom token embedding layer with TensorFlow"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [],
   "source": [
    "# Create token embedding layer\n",
    "token_embed = layers.Embedding(input_dim=len(rct_20k_text_vocab), # length of vocabulary\n",
    "                               output_dim=128, # Note: different embedding sizes result in drastically different numbers of parameters to train\n",
    "                               # Use masking to handle variable sequence lengths (save space when there are lots of 0s)\n",
    "                               mask_zero=True,\n",
    "                               name=\"token_embedding\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-20T02:13:24.008457Z",
     "start_time": "2023-06-20T02:13:24.002738Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence before vectorization:\n",
      "bevacizumab , a recombinant humanized monoclonal antibody against vascular endothelial growth factor , was approved by the us food and drug administration for the treatment of advanced non-small-cell lung cancer ( nsclc ) in combination with carboplatin and paclitaxel .\n",
      "\n",
      "Sentence after vectorization (before embedding):\n",
      "[[ 1034     8  2653 10727  3440  1029   644   758  1033   621   432    10\n",
      "   1824    22     2   850   661     3   300   288    11     2    19     4\n",
      "    588  4023   489   135  1783     5   269     7  3000     3  2118     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0]]\n",
      "\n",
      "Sentence after embedding:\n",
      "[[[ 0.03827921 -0.04521522  0.04744944 ...  0.02669594  0.01075544\n",
      "    0.02892593]\n",
      "  [-0.00809836 -0.0445235   0.03313268 ...  0.01471904  0.01583728\n",
      "   -0.01315622]\n",
      "  [-0.01116868 -0.02111322  0.00291816 ...  0.03988428 -0.0457245\n",
      "    0.02335251]\n",
      "  ...\n",
      "  [ 0.03694284 -0.02536092  0.02098861 ...  0.02924211  0.04143231\n",
      "   -0.03317702]\n",
      "  [ 0.03694284 -0.02536092  0.02098861 ...  0.02924211  0.04143231\n",
      "   -0.03317702]\n",
      "  [ 0.03694284 -0.02536092  0.02098861 ...  0.02924211  0.04143231\n",
      "   -0.03317702]]]\n",
      "\n",
      "Embedded sentence shape: (1, 55, 128)\n"
     ]
    }
   ],
   "source": [
    "# Show example embedding\n",
    "print(f\"Sentence before vectorization:\\n{target_sentence}\\n\")\n",
    "vectorized_sentence = text_vectorizer([target_sentence])\n",
    "print(f\"Sentence after vectorization (before embedding):\\n{vectorized_sentence}\\n\")\n",
    "embedded_sentence = token_embed(vectorized_sentence)\n",
    "print(f\"Sentence after embedding:\\n{embedded_sentence}\\n\")\n",
    "print(f\"Embedded sentence shape: {embedded_sentence.shape}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-20T02:13:48.759066Z",
     "start_time": "2023-06-20T02:13:48.713215Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Creating fast loading dataset with the TensorFlow tf.data API\n",
    "- tf.data makes training and inference faster"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [
    {
     "data": {
      "text/plain": "<_TensorSliceDataset element_spec=(TensorSpec(shape=(), dtype=tf.string, name=None), TensorSpec(shape=(5,), dtype=tf.float64, name=None))>"
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Turn our data into TensorFlow Datasets\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_sentences, train_labels_one_hot))\n",
    "valid_dataset = tf.data.Dataset.from_tensor_slices((val_sentences, val_labels_one_hot))\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((test_sentences, test_labels_one_hot))\n",
    "\n",
    "train_dataset"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-20T02:17:43.711290Z",
     "start_time": "2023-06-20T02:17:43.322434Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [
    {
     "data": {
      "text/plain": "<_PrefetchDataset element_spec=(TensorSpec(shape=(None,), dtype=tf.string, name=None), TensorSpec(shape=(None, 5), dtype=tf.float64, name=None))>"
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take the TensorSliceDataset's and turn them into prefetched batches\n",
    "train_dataset = train_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "valid_dataset = valid_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "test_dataset = test_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "train_dataset"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-20T02:18:14.462559Z",
     "start_time": "2023-06-20T02:18:14.450886Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model 1: Building, fitting and evaluating a Conv1D with token embeddings"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 1)]               0         \n",
      "                                                                 \n",
      " text_vectorization (TextVec  (None, 55)               0         \n",
      " torization)                                                     \n",
      "                                                                 \n",
      " token_embedding (Embedding)  (None, 55, 128)          8299648   \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 55, 64)            41024     \n",
      "                                                                 \n",
      " global_average_pooling1d (G  (None, 64)               0         \n",
      " lobalAveragePooling1D)                                          \n",
      "                                                                 \n",
      " dense (Dense)               (None, 5)                 325       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,340,997\n",
      "Total params: 8,340,997\n",
      "Trainable params: 8,340,997\n"
     ]
    }
   ],
   "source": [
    "# Create 1D convolutional model to process sequences\n",
    "inputs = layers.Input(shape=(1,), dtype=tf.string)\n",
    "text_vectors = text_vectorizer(inputs) # vectorize text inputs\n",
    "token_embeddings = token_embed(text_vectors) # create embedding\n",
    "x = layers.Conv1D(64, kernel_size=5, padding=\"same\", activation=\"relu\")(token_embeddings)\n",
    "x = layers.GlobalAveragePooling1D()(x) # condense the output of our feature vector\n",
    "outputs = layers.Dense(num_classes, activation=\"softmax\")(x)\n",
    "model_1 = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "# Compile\n",
    "model_1.compile(loss=\"categorical_crossentropy\", # if your labels are integer form (not one hot) use sparse_categorical_crossentropy\n",
    "                optimizer=tf.keras.optimizers.Adam(),\n",
    "                metrics=[\"accuracy\"])\n",
    "\n",
    "model_1.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-20T02:22:44.996823Z",
     "start_time": "2023-06-20T02:22:44.932646Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "562/562 [==============================] - 16s 27ms/step - loss: 0.9133 - accuracy: 0.6408 - val_loss: 0.6846 - val_accuracy: 0.7387\n",
      "Epoch 2/3\n",
      "562/562 [==============================] - 17s 30ms/step - loss: 0.6576 - accuracy: 0.7566 - val_loss: 0.6312 - val_accuracy: 0.7699\n",
      "Epoch 3/3\n",
      "562/562 [==============================] - 16s 29ms/step - loss: 0.6160 - accuracy: 0.7760 - val_loss: 0.5954 - val_accuracy: 0.7859\n"
     ]
    }
   ],
   "source": [
    "model_1_history = model_1.fit(train_dataset,\n",
    "                              steps_per_epoch=int(0.1 * len(train_dataset)), # only fit on 10% of batches for faster training time\n",
    "                              epochs=3,\n",
    "                              validation_data=valid_dataset,\n",
    "                              validation_steps=int(0.1 * len(valid_dataset))) # only validate on 10% of batches"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-20T02:23:49.181134Z",
     "start_time": "2023-06-20T02:23:00.711811Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "945/945 [==============================] - 2s 2ms/step - loss: 0.5975 - accuracy: 0.7866\n"
     ]
    },
    {
     "data": {
      "text/plain": "[0.5975086092948914, 0.7865749001502991]"
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate on whole validation dataset (we only validated on 10% of batches during training)\n",
    "model_1.evaluate(valid_dataset)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-20T02:23:50.836727Z",
     "start_time": "2023-06-20T02:23:49.185621Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "945/945 [==============================] - 2s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": "array([[4.6978363e-01, 1.8909685e-01, 7.0518017e-02, 2.3731594e-01,\n        3.3285543e-02],\n       [4.0018934e-01, 3.1160948e-01, 1.1331222e-02, 2.6845714e-01,\n        8.4128175e-03],\n       [1.3322151e-01, 1.0034118e-02, 1.7154962e-03, 8.5499096e-01,\n        3.7964604e-05],\n       ...,\n       [8.3113864e-06, 9.8632544e-04, 8.3496154e-04, 2.2218751e-06,\n        9.9816811e-01],\n       [5.4128449e-02, 4.7378853e-01, 9.4191529e-02, 6.0807660e-02,\n        3.1708390e-01],\n       [1.8071894e-01, 6.5980923e-01, 4.9003173e-02, 5.9015468e-02,\n        5.1453199e-02]], dtype=float32)"
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions (our model outputs prediction probabilities for each class)\n",
    "model_1_pred_probs = model_1.predict(valid_dataset)\n",
    "model_1_pred_probs"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-20T02:23:52.517118Z",
     "start_time": "2023-06-20T02:23:50.838224Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(30212,), dtype=int64, numpy=array([0, 0, 3, ..., 4, 1, 1])>"
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert pred probs to classes\n",
    "model_1_preds = tf.argmax(model_1_pred_probs, axis=1)\n",
    "model_1_preds"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-20T02:24:20.870163Z",
     "start_time": "2023-06-20T02:24:20.853992Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [
    {
     "data": {
      "text/plain": "{'accuracy': 0.7865748709122203,\n 'precision': 0.7839974136046598,\n 'recall': 0.7865748709122203,\n 'f1': 0.7845653650545621}"
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate model_1 results\n",
    "model_1_results = calculate_results(y_true=val_labels_encoded,\n",
    "                                    y_pred=model_1_preds)\n",
    "model_1_results"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-20T02:24:26.162387Z",
     "start_time": "2023-06-20T02:24:26.150631Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Preparing a pretrained embedding layer from TensorFlow Hub for Model 2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [],
   "source": [
    "# Download pretrained TensorFlow Hub USE\n",
    "import tensorflow_hub as hub\n",
    "tf_hub_embedding_layer = hub.KerasLayer(\"https://tfhub.dev/google/universal-sentence-encoder/4\",\n",
    "                                        trainable=False,\n",
    "                                        name=\"universal_sentence_encoder\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-20T02:27:59.538890Z",
     "start_time": "2023-06-20T02:27:56.161239Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random training sentence:\n",
      "there was a single major complication of venous perforation following cba .\n",
      "\n",
      "Sentence after embedding:\n",
      "[-0.06793508  0.01446156  0.06879434 -0.00310257  0.01858308 -0.08894235\n",
      "  0.0331874  -0.03638689  0.05227499 -0.01262461  0.07116918 -0.05454183\n",
      " -0.02948185  0.03249654 -0.02860014 -0.0136672  -0.07633116  0.0541204\n",
      " -0.01787421  0.04236537 -0.06868559  0.08292715 -0.01795826  0.02296084\n",
      " -0.05634724 -0.05493828  0.02286644 -0.01015005 -0.01106641 -0.04628155] (truncated output)...\n",
      "\n",
      "Length of sentence embedding:\n",
      "512\n"
     ]
    }
   ],
   "source": [
    "# Test out the embedding on a random sentence\n",
    "random_training_sentence = random.choice(train_sentences)\n",
    "print(f\"Random training sentence:\\n{random_training_sentence}\\n\")\n",
    "use_embedded_sentence = tf_hub_embedding_layer([random_training_sentence])\n",
    "print(f\"Sentence after embedding:\\n{use_embedded_sentence[0][:30]} (truncated output)...\\n\")\n",
    "print(f\"Length of sentence embedding:\\n{len(use_embedded_sentence[0])}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-20T02:28:56.777762Z",
     "start_time": "2023-06-20T02:28:56.641105Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Building and fitting an NLP feature extraction model from TensorFlow Hub"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    }
   ],
   "source": [
    "# Define feature extractor model using TF Hub layer\n",
    "inputs = layers.Input(shape=[], dtype=tf.string)\n",
    "pretrained_embedding = tf_hub_embedding_layer(inputs) # tokenize text and create embedding\n",
    "x = layers.Dense(128, activation=\"relu\")(pretrained_embedding) # add a fully connected layer on top of the embedding\n",
    "# Note: Could add more layers here\n",
    "outputs = layers.Dense(5, activation=\"softmax\")(x) # create the output layer\n",
    "model_2 = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "# Compile the model\n",
    "model_2.compile(loss=\"categorical_crossentropy\",\n",
    "                optimizer=tf.keras.optimizers.Adam(),\n",
    "                metrics=[\"accuracy\"])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-20T02:29:58.956476Z",
     "start_time": "2023-06-20T02:29:58.723569Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None,)]                 0         \n",
      "                                                                 \n",
      " universal_sentence_encoder   (None, 512)              256797824 \n",
      " (KerasLayer)                                                    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 128)               65664     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 5)                 645       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 256,864,133\n",
      "Trainable params: 66,309\n",
      "Non-trainable params: 256,797,824\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_2.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-20T02:30:25.912036Z",
     "start_time": "2023-06-20T02:30:25.904245Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "562/562 [==============================] - 4s 6ms/step - loss: 0.9200 - accuracy: 0.6458 - val_loss: 0.7984 - val_accuracy: 0.6885\n",
      "Epoch 2/3\n",
      "562/562 [==============================] - 2s 4ms/step - loss: 0.7708 - accuracy: 0.7011 - val_loss: 0.7579 - val_accuracy: 0.7064\n",
      "Epoch 3/3\n",
      "562/562 [==============================] - 2s 4ms/step - loss: 0.7548 - accuracy: 0.7111 - val_loss: 0.7432 - val_accuracy: 0.7148\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x2936bc610>"
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit feature extractor model for 3 epochs\n",
    "model_2.fit(train_dataset,\n",
    "            steps_per_epoch=int(0.1 * len(train_dataset)),\n",
    "            epochs=3,\n",
    "            validation_data=valid_dataset,\n",
    "            validation_steps=int(0.1 * len(valid_dataset)))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-20T02:30:42.906376Z",
     "start_time": "2023-06-20T02:30:34.121097Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "945/945 [==============================] - 4s 4ms/step - loss: 0.7442 - accuracy: 0.7126\n"
     ]
    },
    {
     "data": {
      "text/plain": "[0.74423748254776, 0.7125645279884338]"
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate on whole validation dataset\n",
    "model_2.evaluate(valid_dataset)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-20T02:30:47.174885Z",
     "start_time": "2023-06-20T02:30:43.552803Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "945/945 [==============================] - 4s 4ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": "array([[0.42307085, 0.37616315, 0.00230146, 0.18743274, 0.01103178],\n       [0.36432818, 0.49172342, 0.00338418, 0.13729593, 0.00326817],\n       [0.21391456, 0.17866226, 0.01946404, 0.5501474 , 0.03781172],\n       ...,\n       [0.00189773, 0.00770356, 0.05400246, 0.00107354, 0.9353227 ],\n       [0.00366194, 0.04906245, 0.19394591, 0.00143365, 0.751896  ],\n       [0.14241636, 0.2819693 , 0.5179311 , 0.00561396, 0.05206926]],\n      dtype=float32)"
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions with feature extraction model\n",
    "model_2_pred_probs = model_2.predict(valid_dataset)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-20T02:30:58.056808Z",
     "start_time": "2023-06-20T02:30:54.212918Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(30212,), dtype=int64, numpy=array([0, 1, 3, ..., 4, 4, 2])>"
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2_preds = tf.argmax(model_2_pred_probs, axis=1)\n",
    "model_2_preds"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-20T02:33:08.195558Z",
     "start_time": "2023-06-20T02:33:08.188720Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [
    {
     "data": {
      "text/plain": "{'accuracy': 0.7125645438898451,\n 'precision': 0.712907265386399,\n 'recall': 0.7125645438898451,\n 'f1': 0.7095609938447329}"
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate results from TF Hub pretrained embeddings results on validation set\n",
    "model_2_results = calculate_results(y_true=val_labels_encoded,\n",
    "                                    y_pred=model_2_preds)\n",
    "model_2_results"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-20T02:33:16.756407Z",
     "start_time": "2023-06-20T02:33:16.744823Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
