{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-05-15T20:53:58.671021Z",
     "start_time": "2023-05-15T20:53:58.630176Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf # pip install tensorflow-macos\n",
    "import os\n",
    "tf.random.set_seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# The typical architecture of a Recurrent Neural Network (RNN)\n",
    "- The premise of an RNN is simple: use information from the past to help you with the future (this is where the term recurrent comes from). In other words, take an input (X) and compute an output (y) based on all previous inputs.\n",
    "\n",
    "When an RNN looks at a sequence of text (already in numerical form), the patterns it learns are continually updated based on the order of the sequence.\n",
    "\n",
    "For a simple example, take two sentences:\n",
    "\n",
    "1. Massive earthquake last week, no?\n",
    "2. No massive earthquake last week.\n",
    "\n",
    "Both contain exactly the same words but have different meaning. The order of the words determines the meaning (one could argue punctuation marks also dictate the meaning but for simplicity sake, let's stay focused on the words).\n",
    "\n",
    "### actual architecture\n",
    "1. input layer\n",
    "2. text vectorization layer\n",
    "3. embedding\n",
    "4. RNN cell(s)\n",
    "5. Hidden activation\n",
    "6. pooling layer (sometimes, usually for Conv1D models)\n",
    "7. fully connected layer\n",
    "8. output layer\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Preparing a notebook for our first NLP with TensorFlow project\n",
    "[data from kaggle](https://www.kaggle.com/competitions/nlp-getting-started/leaderboard)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "from helper_functions import create_tensorboard_callback, unzip_data, plot_loss_curves, compare_historys"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-15T20:53:58.679039Z",
     "start_time": "2023-05-15T20:53:58.677675Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "zip_path = \"nlp_getting_started.zip\"\n",
    "if not os.path.isfile(zip_path):\n",
    "    os.chdir(\"data\")\n",
    "unzip_data(zip_path)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-15T20:53:58.704619Z",
     "start_time": "2023-05-15T20:53:58.685885Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Becoming one with the data and visualizing a text dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [],
   "source": [
    "# we can use pandas because the data isn't too big\n",
    "train_df = pd.read_csv(\"train.csv\")\n",
    "test_df = pd.read_csv(\"test.csv\")\n",
    "\n",
    "# shuffle training data\n",
    "train_df = train_df.sample(frac=1, random_state=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-15T20:53:58.764667Z",
     "start_time": "2023-05-15T20:53:58.717449Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "data": {
      "text/plain": "         id               keyword                  location   \n3228   4632  emergency%20services   Sydney, New South Wales  \\\n3706   5271                  fear                       NaN   \n6957   9982               tsunami         Land Of The Kings   \n2887   4149                 drown                       NaN   \n7464  10680                wounds  cody, austin follows ?*?   \n\n                                                   text  target  \n3228  Goulburn man Henry Van Bilsen missing: Emergen...       1  \n3706  The things we fear most in organizations--fluc...       0  \n6957                            @tsunami_esh ?? hey Esh       0  \n2887  @POTUS you until you drown by water entering t...       0  \n7464  Crawling in my skin\\nThese wounds they will no...       1  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>keyword</th>\n      <th>location</th>\n      <th>text</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>3228</th>\n      <td>4632</td>\n      <td>emergency%20services</td>\n      <td>Sydney, New South Wales</td>\n      <td>Goulburn man Henry Van Bilsen missing: Emergen...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3706</th>\n      <td>5271</td>\n      <td>fear</td>\n      <td>NaN</td>\n      <td>The things we fear most in organizations--fluc...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>6957</th>\n      <td>9982</td>\n      <td>tsunami</td>\n      <td>Land Of The Kings</td>\n      <td>@tsunami_esh ?? hey Esh</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2887</th>\n      <td>4149</td>\n      <td>drown</td>\n      <td>NaN</td>\n      <td>@POTUS you until you drown by water entering t...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>7464</th>\n      <td>10680</td>\n      <td>wounds</td>\n      <td>cody, austin follows ?*?</td>\n      <td>Crawling in my skin\\nThese wounds they will no...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-15T20:53:58.778567Z",
     "start_time": "2023-05-15T20:53:58.776604Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "data": {
      "text/plain": "'Goulburn man Henry Van Bilsen missing: Emergency services are searching for a Goulburn man who disappeared from his\\x89Û_ http://t.co/z99pKJzTRp'"
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.iloc[0][\"text\"]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-15T20:53:58.783182Z",
     "start_time": "2023-05-15T20:53:58.781504Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "data": {
      "text/plain": "   id keyword location                                               text\n0   0     NaN      NaN                 Just happened a terrible car crash\n1   2     NaN      NaN  Heard about #earthquake is different cities, s...\n2   3     NaN      NaN  there is a forest fire at spot pond, geese are...\n3   9     NaN      NaN           Apocalypse lighting. #Spokane #wildfires\n4  11     NaN      NaN      Typhoon Soudelor kills 28 in China and Taiwan",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>keyword</th>\n      <th>location</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Just happened a terrible car crash</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Heard about #earthquake is different cities, s...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>there is a forest fire at spot pond, geese are...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>9</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Apocalypse lighting. #Spokane #wildfires</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>11</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test data frame looks the same but without targets\n",
    "test_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-15T20:53:58.797212Z",
     "start_time": "2023-05-15T20:53:58.786025Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "data": {
      "text/plain": "target\n0    4342\n1    3271\nName: count, dtype: int64"
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[\"target\"].value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-15T20:53:58.852261Z",
     "start_time": "2023-05-15T20:53:58.795665Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7613 3263\n"
     ]
    }
   ],
   "source": [
    "print(len(train_df), len(test_df))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-15T20:53:58.852482Z",
     "start_time": "2023-05-15T20:53:58.798641Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target: 1 (real disaster)\n",
      "Text:\n",
      "Another entity forced to close in Montego Bay as a result of the collapsed sewer line #TVJNews\n",
      "\n",
      "---\n",
      "\n",
      "Target: 1 (real disaster)\n",
      "Text:\n",
      "@Kinder_Morgan can'twon't tell @cityofkamloops how they'd respond to an oil spill. Trust them? See Sec 4.2 #Kamloops http://t.co/TA6N9sZyfP\n",
      "\n",
      "---\n",
      "\n",
      "Target: 0 (not real disaster)\n",
      "Text:\n",
      "@BaseballQuotes1 I have a 32 inch dynasty\n",
      "\n",
      "---\n",
      "\n",
      "Target: 1 (real disaster)\n",
      "Text:\n",
      "Good thing there was actually just a legit fire in the mall and nobody evacuated!!\n",
      "\n",
      "---\n",
      "\n",
      "Target: 0 (not real disaster)\n",
      "Text:\n",
      "Listen LIve: http://t.co/1puLaekxcq #Author #Interview Beth Underwood of #Gravity on #Military #Mom #TalkRadio\n",
      "\n",
      "---\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# let's visualize some random samples\n",
    "import random\n",
    "random_index = random.randint(0, len(train_df)-5)\n",
    "for row in train_df[[\"text\", \"target\"]][random_index:random_index+5].itertuples():\n",
    "    _, text, target = row\n",
    "    print(f\"Target: {target}\", \"(real disaster)\" if target > 0 else \"(not real disaster)\")\n",
    "    print(f\"Text:\\n{text}\\n\")\n",
    "    print(\"---\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-15T20:53:58.865254Z",
     "start_time": "2023-05-15T20:53:58.809131Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Splitting data into training and validation sets"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_sentences, val_sentences, train_labels, val_labels = train_test_split(train_df[\"text\"].to_numpy(),\n",
    "                                                                            train_df[\"target\"].to_numpy(),\n",
    "                                                                            test_size=0.1,\n",
    "                                                                            random_state=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-15T20:53:58.914968Z",
     "start_time": "2023-05-15T20:53:58.817734Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6851 6851 762 762\n"
     ]
    }
   ],
   "source": [
    "print(len(train_sentences), len(train_labels), len(val_sentences), len(val_labels))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-15T20:53:58.915215Z",
     "start_time": "2023-05-15T20:53:58.833986Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [
    {
     "data": {
      "text/plain": "array(['Rly tragedy in MP: Some live to recount horror: \\x89ÛÏWhen I saw coaches of my train plunging into water I called my daughters and said t...',\n       'A river of lava in the sky this evening! It was indeed a beautiful sunset sky tonight. (8-4-15) http://t.co/17EGMlNi80',\n       'Los Angeles Times: Arson suspect linked to 30 fires caught in Northern ... - http://t.co/xwMs1AWW8m #NewsInTweets http://t.co/TE2YeRugsi',\n       ...,\n       \"When you lowkey already know you're gonna drown in school this year :) http://t.co/aCMrm833zq\",\n       '@JamesMelville Some old testimony of weapons used to promote conflicts\\nTactics - corruption &amp; infiltration of groups\\nhttps://t.co/cyU8zxw1oH',\n       \"Just got evacuated from the movie theatre for an emergency. Saw people running from another they're.\"],\n      dtype=object)"
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sentences[:-10]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-15T20:53:58.915520Z",
     "start_time": "2023-05-15T20:53:58.834548Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [
    {
     "data": {
      "text/plain": "array([1, 0, 1, ..., 0, 0, 1])"
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels[:-10]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-15T20:53:58.915773Z",
     "start_time": "2023-05-15T20:53:58.851345Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Converting text data to numbers using tokenisation and embeddings (overview)\n",
    "### Tokenization\n",
    "- A straight mapping from word or character or sub-word to a numerical value. There are three main levels of tokenization:\n",
    "1. Using word-level tokenization with the sentence \"I love TensorFlow\" might result in \"I\" being 0, \"love\" being 1 and \"TensorFlow\" being 2. In this case, every word in a sequence considered a single token.\n",
    "2. Character-level tokenization, such as converting the letters A-Z to values 1-26. In this case, every character in a sequence considered a single token.\n",
    "3. Sub-word tokenization is in between word-level and character-level tokenization. It involves breaking invidual words into smaller parts and then converting those smaller parts into numbers. For example, \"my favourite food is pineapple pizza\" might become \"my, fav, avour, rite, fo, oo, od, is, pin, ine, app, le, piz, za\". After doing this, these sub-words would then be mapped to a numerical value. In this case, every word could be considered multiple tokens.\n",
    "\n",
    "\n",
    "### Embeddings\n",
    "- An embedding is a representation of natural language which can be learned. Representation comes in the form of a feature vector. For example, the word \"dance\" could be represented by the 5-dimensional vector [-0.8547, 0.4559, -0.3332, 0.9877, 0.1112]. It's important to note here, the size of the feature vector is tuneable. There are two ways to use embeddings:\n",
    "1. Create your own embedding - Once your text has been turned into numbers (required for an embedding), you can put them through an embedding layer (such as tf.keras.layers.Embedding) and an embedding representation will be learned during model training.\n",
    "2. Reuse a pre-learned embedding - Many pre-trained embeddings exist online. These pre-trained embeddings have often been learned on large corpuses of text (such as all of Wikipedia) and thus have a good underlying representation of natural language. You can use a pre-trained embedding to initialize your model and fine-tune it to your own specific task."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Setting up a TensorFlow TextVectorization layer to convert text to numbers"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import TextVectorization"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-15T20:53:58.936282Z",
     "start_time": "2023-05-15T20:53:58.862620Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [],
   "source": [
    "# these are the default parameters. this cell is just for demonstration\n",
    "text_vectorizer = TextVectorization(max_tokens=None, # how many words in the vocabulary (all of the different words in your text)\n",
    "                                    standardize=\"lower_and_strip_punctuation\", # how to process text\n",
    "                                    split=\"whitespace\", # how to split tokens\n",
    "                                    ngrams=None, # create groups of n-words?\n",
    "                                    output_mode=\"int\", # how to map tokens to numbers\n",
    "                                    output_sequence_length=None) # how long should the output sequence of tokens be?\n",
    "                                    # pad_to_max_tokens=True) # Not valid if using max_tokens=None"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-15T20:53:58.974916Z",
     "start_time": "2023-05-15T20:53:58.943786Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "data": {
      "text/plain": "15"
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find average number of tokens (words) in training Tweets\n",
    "round(sum([len(i.split()) for i in train_sentences])/len(train_sentences))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-15T20:53:58.976094Z",
     "start_time": "2023-05-15T20:53:58.960758Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [],
   "source": [
    "# Setup text vectorization with custom variables\n",
    "max_vocab_length = 10000 # max number of words to have in our vocabulary\n",
    "max_length = 15 # max length our sequences will be (e.g. how many words from a Tweet does our model see?)\n",
    "\n",
    "text_vectorizer = TextVectorization(max_tokens=max_vocab_length,\n",
    "                                    output_mode=\"int\",\n",
    "                                    output_sequence_length=max_length)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-15T20:53:58.991266Z",
     "start_time": "2023-05-15T20:53:58.980301Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Mapping the TextVectorization layer to text data and turning it into numbers"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [],
   "source": [
    "# Fit the text vectorizer to the training text\n",
    "text_vectorizer.adapt(train_sentences)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-15T20:53:59.312143Z",
     "start_time": "2023-05-15T20:53:58.985327Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(1, 15), dtype=int64, numpy=\narray([[319,   3, 199,   4,  13, 699,   0,   0,   0,   0,   0,   0,   0,\n          0,   0]])>"
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create sample sentence and tokenize it\n",
    "sample_sentence = \"There's a flood in my street!\"\n",
    "text_vectorizer([sample_sentence])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-15T20:53:59.337041Z",
     "start_time": "2023-05-15T20:53:59.314294Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original text:\n",
      "Listen to Landslide by Oh Wonder #SoundCloud https://t.co/SJkgJxff2r      \n",
      "\n",
      "Vectorized version:\n"
     ]
    },
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(1, 15), dtype=int64, numpy=\narray([[ 800,    5,  326,   18,  471,  921, 2282,    1,    0,    0,    0,\n           0,    0,    0,    0]])>"
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Choose a random sentence from the training dataset and tokenize it\n",
    "random_sentence = random.choice(train_sentences)\n",
    "print(f\"Original text:\\n{random_sentence}\\\n",
    "      \\n\\nVectorized version:\")\n",
    "text_vectorizer([random_sentence])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-15T20:53:59.342739Z",
     "start_time": "2023-05-15T20:53:59.337193Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words in vocab: 10000\n",
      "Top 5 most common words: ['', '[UNK]', 'the', 'a', 'in']\n",
      "Bottom 5 least common words: ['palmer', 'palm', 'palinfoen', 'palestinian\\x89Û', 'paleface']\n"
     ]
    }
   ],
   "source": [
    "# Get the unique words in the vocabulary\n",
    "words_in_vocab = text_vectorizer.get_vocabulary()\n",
    "top_5_words = words_in_vocab[:5] # most common tokens (notice the [UNK] token for \"unknown\" words)\n",
    "bottom_5_words = words_in_vocab[-5:] # least common tokens\n",
    "print(f\"Number of words in vocab: {len(words_in_vocab)}\")\n",
    "print(f\"Top 5 most common words: {top_5_words}\")\n",
    "print(f\"Bottom 5 least common words: {bottom_5_words}\")\n",
    "\n",
    "# UNK is unknown token which replaces uncommon words. increasing max tokens will reduce it's popularity"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-15T20:53:59.355876Z",
     "start_time": "2023-05-15T20:53:59.344573Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Creating an Embedding layer to turn tokenised text into embedding vectors"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [],
   "source": [
    "embedding = tf.keras.layers.Embedding(input_dim=max_vocab_length,  # set input shape\n",
    "                                      output_dim=128,  # a common starting point, multiples of 8 tend to run faster\n",
    "                                      input_length=max_length  # how long is the input?\n",
    "                                      )"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-15T20:57:51.572479Z",
     "start_time": "2023-05-15T20:57:51.554866Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original text:\n",
      "http://t.co/IQoWZgvZNl #LatestNews #CNBC #CNN\n",
      "\n",
      "The anniversary of the devastation wrought by the first military use of an atomic weapon cÛ_      \n",
      "\n",
      "Embedded version:\n"
     ]
    },
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(1, 15, 128), dtype=float32, numpy=\narray([[[-1.18612275e-02, -1.07072815e-02, -4.81600277e-02, ...,\n         -1.25226974e-02, -3.41610685e-02, -8.90917704e-03],\n        [-1.88432224e-02, -1.40149705e-02, -2.46337410e-02, ...,\n         -2.49969363e-02, -2.39292141e-02, -2.44157314e-02],\n        [ 1.67889632e-02,  4.60782684e-02, -2.00289972e-02, ...,\n         -4.56779078e-03,  3.40327136e-02, -7.32109696e-03],\n        ...,\n        [-3.74088399e-02, -3.39595228e-03,  5.63403219e-03, ...,\n         -4.78196256e-02, -1.27853379e-02, -3.02458759e-02],\n        [ 1.26141421e-02, -1.77694187e-02,  1.15094297e-02, ...,\n         -3.73956934e-02,  4.82693203e-02,  4.85223792e-02],\n        [-7.26636499e-03, -1.79602727e-02,  2.03935765e-02, ...,\n          1.06664672e-02, -4.22287844e-02, -1.66408718e-05]]],\n      dtype=float32)>"
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get a random sentence from training set\n",
    "random_sentence = random.choice(train_sentences)\n",
    "print(f\"Original text:\\n{random_sentence}\\\n",
    "      \\n\\nEmbedded version:\")\n",
    "\n",
    "# Embed the random sentence (turn it into numerical representation)\n",
    "sample_embed = embedding(text_vectorizer([random_sentence]))\n",
    "sample_embed"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-15T20:58:37.266725Z",
     "start_time": "2023-05-15T20:58:37.250604Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(128,), dtype=float32, numpy=\narray([-0.01186123, -0.01070728, -0.04816003, -0.03321858, -0.02307776,\n        0.0132594 , -0.00074885,  0.01008773,  0.0070513 ,  0.0351406 ,\n       -0.00474058, -0.03447219,  0.04294902,  0.04649981,  0.03922344,\n       -0.02696341,  0.02332905, -0.04550156,  0.02990261,  0.00118016,\n        0.02699429,  0.01382513,  0.04477722,  0.04552389,  0.03215852,\n        0.0048535 ,  0.01162157, -0.02584219,  0.04267731,  0.03336585,\n        0.03148479,  0.00255237, -0.0123833 ,  0.00050079,  0.02689702,\n        0.01823736, -0.02636553,  0.0053781 ,  0.01813947,  0.04972389,\n        0.02965227, -0.01668971,  0.01329   ,  0.0229053 , -0.03580294,\n       -0.02463925,  0.03761759, -0.00547909,  0.04895378, -0.03167172,\n       -0.00509628,  0.03768371,  0.04807465,  0.01403618,  0.0445391 ,\n       -0.02736946,  0.04780911,  0.00088465,  0.00026884, -0.01776893,\n       -0.04434185, -0.01490859,  0.03036982, -0.01646664, -0.03041079,\n       -0.03669778,  0.03005696, -0.01965907, -0.02646245,  0.01773812,\n       -0.04555804, -0.02351166,  0.04152234,  0.00678691,  0.03448964,\n       -0.03524558,  0.044084  ,  0.0421913 , -0.03289385, -0.04698333,\n        0.01546873, -0.0078945 ,  0.01114347, -0.01329662,  0.03957832,\n       -0.02885891,  0.0146771 , -0.04679929,  0.00899292,  0.02834428,\n        0.02395229, -0.02539049,  0.03277442,  0.01984612, -0.04693825,\n        0.00945667, -0.00064374,  0.00841894,  0.03600571, -0.02455546,\n       -0.009904  , -0.00977026, -0.0112442 ,  0.01157377, -0.02420755,\n        0.03219629, -0.04441773, -0.02619061,  0.04349147,  0.03461728,\n       -0.02202166,  0.0408519 , -0.02797299, -0.00670556,  0.04835698,\n       -0.04778079,  0.02356917,  0.01436952, -0.03844526, -0.01362206,\n        0.02155321, -0.04909034,  0.03376398, -0.02543241, -0.0063551 ,\n       -0.0125227 , -0.03416107, -0.00890918], dtype=float32)>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "TensorShape([128])"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "'http://t.co/IQoWZgvZNl #LatestNews #CNBC #CNN\\n\\nThe anniversary of the devastation wrought by the first military use of an atomic weapon c\\x89Û_'"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check out a single token's embedding\n",
    "display(sample_embed[0][0])\n",
    "display(sample_embed[0][0].shape)\n",
    "display(random_sentence)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-15T21:00:52.617886Z",
     "start_time": "2023-05-15T21:00:52.614446Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# the various modelling experiments we're going to run\n",
    "- [Model 0: Sklearn Naive Bayes (baseline)](https://scikit-learn.org/stable/modules/naive_bayes.html)\n",
    "- Model 1: Feed-forward neural network (dense model)\n",
    "- Model 2: LSTM model\n",
    "- Model 3: GRU model\n",
    "- Model 4: Bidirectional-LSTM model\n",
    "- Model 5: 1D Convolutional Neural Network\n",
    "- Model 6: TensorFlow Hub Pretrained Feature Extractor\n",
    "- Model 7: Same as model 6 with 10% of training data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model 0: Building a baseline model to try and improve upon [Sklearn Naive Bayes (baseline)](https://scikit-learn.org/stable/modules/naive_bayes.html)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [
    {
     "data": {
      "text/plain": "Pipeline(steps=[('tfidf', TfidfVectorizer()), ('clf', MultinomialNB())])",
      "text/html": "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;, TfidfVectorizer()), (&#x27;clf&#x27;, MultinomialNB())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;, TfidfVectorizer()), (&#x27;clf&#x27;, MultinomialNB())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div></div></div>"
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Create tokenization and modelling pipeline (pipeline is a bit like tf.keras.models.Sequential()\n",
    "model_0 = Pipeline([\n",
    "                    (\"tfidf\", TfidfVectorizer()), # convert words to numbers using tfidf\n",
    "                    (\"clf\", MultinomialNB()) # model the text\n",
    "])\n",
    "\n",
    "# Fit the pipeline to the training data\n",
    "model_0.fit(train_sentences, train_labels)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-15T21:08:53.863074Z",
     "start_time": "2023-05-15T21:08:53.228968Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our baseline model achieves an accuracy of: 78.22%\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model:\n",
    "baseline_score = model_0.score(val_sentences, val_labels)\n",
    "print(f\"Our baseline model achieves an accuracy of: {baseline_score*100:.2f}%\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-15T21:09:37.779626Z",
     "start_time": "2023-05-15T21:09:37.772651Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [
    {
     "data": {
      "text/plain": "array([1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0])"
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions\n",
    "baseline_preds = model_0.predict(val_sentences)\n",
    "baseline_preds[:20]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-15T21:10:38.877842Z",
     "start_time": "2023-05-15T21:10:38.868440Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Creating a function to track and evaluate our model's results"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [],
   "source": [
    "# Function to evaluate: accuracy, precision, recall, f1-score\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "def calculate_results(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Calculates model accuracy, precision, recall and f1 score of a binary classification model.\n",
    "    only works for binary classification\n",
    "    Args:\n",
    "    -----\n",
    "    y_true = true labels in the form of a 1D array\n",
    "    y_pred = predicted labels in the form of a 1D array\n",
    "\n",
    "    Returns a dictionary of accuracy, precision, recall, f1-score.\n",
    "    \"\"\"\n",
    "    # Calculate model accuracy\n",
    "    model_accuracy = accuracy_score(y_true, y_pred)\n",
    "    # Calculate model precision, recall and f1 score using \"weighted\" average\n",
    "    model_precision, model_recall, model_f1, _ = precision_recall_fscore_support(y_true, y_pred, average=\"weighted\")\n",
    "    model_results = {\"accuracy\": model_accuracy,\n",
    "                  \"precision\": model_precision,\n",
    "                  \"recall\": model_recall,\n",
    "                  \"f1\": model_f1}\n",
    "    return model_results"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-15T21:17:48.219024Z",
     "start_time": "2023-05-15T21:17:48.216905Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [
    {
     "data": {
      "text/plain": "{'accuracy': 0.7821522309711286,\n 'precision': 0.7922635210264124,\n 'recall': 0.7821522309711286,\n 'f1': 0.7730378142460546}"
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Baseline results\n",
    "baseline_results = calculate_results(y_true=val_labels, y_pred=baseline_preds)\n",
    "baseline_results"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-15T21:17:49.677572Z",
     "start_time": "2023-05-15T21:17:49.672891Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model 1: Building, fitting and evaluating our first deep model (feed forward) on text data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [],
   "source": [
    "# Create tensorboard callback (need to create a new one for each model)\n",
    "from helper_functions import create_tensorboard_callback\n",
    "\n",
    "# Create directory to save TensorBoard logs\n",
    "SAVE_DIR = \"model_logs\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-15T21:20:29.672784Z",
     "start_time": "2023-05-15T21:20:29.671263Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "\n",
    "inputs = layers.Input(shape=(1,), dtype=tf.string)\n",
    "x = text_vectorizer(inputs) # turn the input text into numbers\n",
    "x = embedding(x)  # create embedding of numberized inputs\n",
    "x = layers.GlobalAveragePooling1D()(x) # lower the dimensionality of the embedding\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "model_1 = tf.keras.Model(inputs, outputs, name=\"model_1_dense\") # construct the model"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-15T21:39:55.452452Z",
     "start_time": "2023-05-15T21:39:55.405285Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1_dense\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 1)]               0         \n",
      "                                                                 \n",
      " text_vectorization_4 (TextV  (None, 15)               0         \n",
      " ectorization)                                                   \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, 15, 128)           1280000   \n",
      "                                                                 \n",
      " global_average_pooling1d (G  (None, 128)              0         \n",
      " lobalAveragePooling1D)                                          \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,280,129\n",
      "Trainable params: 1,280,129\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_1.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-15T21:39:56.815139Z",
     "start_time": "2023-05-15T21:39:56.801782Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    }
   ],
   "source": [
    "model_1.compile(loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "                optimizer=tf.keras.optimizers.Adam(),\n",
    "                metrics=[\"accuracy\"])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-15T21:39:58.975685Z",
     "start_time": "2023-05-15T21:39:58.963609Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving TensorBoard log files to: model_logs/simple_dense_model/20230515-173959\n",
      "Epoch 1/5\n",
      "215/215 [==============================] - 1s 5ms/step - loss: 0.6102 - accuracy: 0.6873 - val_loss: 0.5423 - val_accuracy: 0.7572\n",
      "Epoch 2/5\n",
      "215/215 [==============================] - 1s 6ms/step - loss: 0.4385 - accuracy: 0.8221 - val_loss: 0.4912 - val_accuracy: 0.7913\n",
      "Epoch 3/5\n",
      "215/215 [==============================] - 2s 9ms/step - loss: 0.3449 - accuracy: 0.8624 - val_loss: 0.4846 - val_accuracy: 0.7913\n",
      "Epoch 4/5\n",
      "215/215 [==============================] - 2s 10ms/step - loss: 0.2818 - accuracy: 0.8904 - val_loss: 0.4972 - val_accuracy: 0.7966\n",
      "Epoch 5/5\n",
      "215/215 [==============================] - 1s 7ms/step - loss: 0.2342 - accuracy: 0.9136 - val_loss: 0.5178 - val_accuracy: 0.7822\n"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "model_1_history = model_1.fit(train_sentences, # input sentences can be a list of strings due to text preprocessing layer built-in model\n",
    "                              train_labels,\n",
    "                              epochs=5,\n",
    "                              validation_data=(val_sentences, val_labels),\n",
    "                              callbacks=[create_tensorboard_callback(dir_name=SAVE_DIR,\n",
    "                                                                     experiment_name=\"simple_dense_model\")])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-15T21:40:08.142560Z",
     "start_time": "2023-05-15T21:39:59.951888Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 0s 553us/step - loss: 0.5178 - accuracy: 0.7822\n"
     ]
    },
    {
     "data": {
      "text/plain": "[0.5177744626998901, 0.7821522355079651]"
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the results\n",
    "model_1.evaluate(val_sentences, val_labels)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-15T21:40:34.145338Z",
     "start_time": "2023-05-15T21:40:34.091316Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 0s 537us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": "array([[0.9964226 ],\n       [0.9327878 ],\n       [0.8648236 ],\n       [0.00438873],\n       [0.28702542],\n       [0.30479118],\n       [0.85083795],\n       [0.20744666],\n       [0.11996101],\n       [0.06736172]], dtype=float32)"
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1_pred_probs = model_1.predict(val_sentences)\n",
    "model_1_pred_probs[:10] # only print out the first 10 prediction probabilities"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-15T21:42:00.883864Z",
     "start_time": "2023-05-15T21:42:00.755345Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(20,), dtype=float32, numpy=\narray([1., 1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0.,\n       0., 1., 1.], dtype=float32)>"
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Turn prediction probabilities into single-dimension tensor of floats\n",
    "model_1_preds = tf.squeeze(tf.round(model_1_pred_probs)) # squeeze removes single dimensions\n",
    "model_1_preds[:20]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-15T21:42:10.141741Z",
     "start_time": "2023-05-15T21:42:10.134606Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "outputs": [
    {
     "data": {
      "text/plain": "{'accuracy': 0.7821522309711286,\n 'precision': 0.7812870817618385,\n 'recall': 0.7821522309711286,\n 'f1': 0.7792225885166626}"
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate model_1 metrics\n",
    "model_1_results = calculate_results(y_true=val_labels,\n",
    "                                    y_pred=model_1_preds)\n",
    "model_1_results"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-15T21:42:20.785064Z",
     "start_time": "2023-05-15T21:42:20.782543Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "outputs": [
    {
     "data": {
      "text/plain": "array([False, False, False,  True])"
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Is our simple Keras model better than our baseline model?\n",
    "np.array(list(model_1_results.values())) > np.array(list(baseline_results.values()))\n",
    "# nope"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-15T21:46:14.022896Z",
     "start_time": "2023-05-15T21:46:14.013772Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
